{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "car-Cleaning_and_Clustering(v7).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjTKuN4JhxVV",
        "outputId": "010e8603-6cef-4644-8530-4de0930375a6"
      },
      "source": [
        "!pip install kmodes\n",
        "!pip install dtale"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kmodes\n",
            "  Downloading kmodes-0.11.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from kmodes) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.7/dist-packages (from kmodes) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from kmodes) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from kmodes) (1.0.1)\n",
            "Installing collected packages: kmodes\n",
            "Successfully installed kmodes-0.11.0\n",
            "Collecting dtale\n",
            "  Downloading dtale-1.56.0-py2.py3-none-any.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 14.1 MB/s \n",
            "\u001b[?25hCollecting squarify\n",
            "  Downloading squarify-0.4.3-py3-none-any.whl (4.3 kB)\n",
            "Collecting dash-daq\n",
            "  Downloading dash_daq-0.5.0.tar.gz (642 kB)\n",
            "\u001b[K     |████████████████████████████████| 642 kB 49.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from dtale) (3.2.2)\n",
            "Collecting lz4\n",
            "  Downloading lz4-3.1.3-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 75.1 MB/s \n",
            "\u001b[?25hCollecting flask-ngrok\n",
            "  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
            "Collecting dash-bootstrap-components\n",
            "  Downloading dash_bootstrap_components-0.13.0-py3-none-any.whl (197 kB)\n",
            "\u001b[K     |████████████████████████████████| 197 kB 53.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from dtale) (1.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from dtale) (2.6.2)\n",
            "Collecting strsimpy\n",
            "  Downloading strsimpy-0.2.0-py3-none-any.whl (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: xlrd in /usr/local/lib/python3.7/dist-packages (from dtale) (1.1.0)\n",
            "Requirement already satisfied: future>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from dtale) (0.16.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from dtale) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from dtale) (2.23.0)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.7/dist-packages (from dtale) (0.18.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from dtale) (0.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from dtale) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from dtale) (1.19.5)\n",
            "Collecting missingno<=0.4.2\n",
            "  Downloading missingno-0.4.2-py3-none-any.whl (9.7 kB)\n",
            "Collecting ppscore\n",
            "  Downloading ppscore-1.2.0.tar.gz (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from dtale) (0.10.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from dtale) (0.22.2.post1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (from dtale) (2.5.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from dtale) (1.4.1)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from dtale) (1.1.4)\n",
            "Collecting plotly>=5.0.0\n",
            "  Downloading plotly-5.3.1-py2.py3-none-any.whl (23.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.9 MB 13 kB/s \n",
            "\u001b[?25hRequirement already satisfied: itsdangerous in /usr/local/lib/python3.7/dist-packages (from dtale) (1.1.0)\n",
            "Collecting dash-colorscales\n",
            "  Downloading dash_colorscales-0.0.4.tar.gz (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 795 kB/s \n",
            "\u001b[?25hCollecting dash>=1.5.0\n",
            "  Downloading dash-2.0.0-py3-none-any.whl (7.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3 MB 71.3 MB/s \n",
            "\u001b[?25hCollecting Flask-Compress\n",
            "  Downloading Flask_Compress-1.10.1-py3-none-any.whl (7.9 kB)\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9 MB 97 kB/s \n",
            "\u001b[?25hCollecting dash-table==5.0.0\n",
            "  Downloading dash_table-5.0.0.tar.gz (3.4 kB)\n",
            "Collecting dash-core-components==2.0.0\n",
            "  Downloading dash_core_components-2.0.0.tar.gz (3.4 kB)\n",
            "Collecting dash-html-components==2.0.0\n",
            "  Downloading dash_html_components-2.0.0.tar.gz (3.8 kB)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask->dtale) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask->dtale) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->dtale) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask->dtale) (2.0.1)\n",
            "Collecting tenacity>=6.2.0\n",
            "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
            "Collecting brotli\n",
            "  Downloading Brotli-1.0.9-cp37-cp37m-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[K     |████████████████████████████████| 357 kB 44.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->dtale) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->dtale) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->dtale) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->dtale) (2.4.7)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.7/dist-packages (from openpyxl->dtale) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->dtale) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->dtale) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->dtale) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->dtale) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->dtale) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->dtale) (3.0.4)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->dtale) (0.5.1)\n",
            "Requirement already satisfied: setuptools>=40.4 in /usr/local/lib/python3.7/dist-packages (from xarray->dtale) (57.4.0)\n",
            "Building wheels for collected packages: dash-core-components, dash-html-components, dash-table, dash-colorscales, dash-daq, ppscore\n",
            "  Building wheel for dash-core-components (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dash-core-components: filename=dash_core_components-2.0.0-py3-none-any.whl size=3821 sha256=7adf0b8624cedcb686dedf6c2a947bd8aa9dc2edc8b47055e1f274f8f8aee095\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/f9/c7/1a6437d794ed753ea9bc9079e761d4fc803a1f1f5d3697b9ec\n",
            "  Building wheel for dash-html-components (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dash-html-components: filename=dash_html_components-2.0.0-py3-none-any.whl size=4089 sha256=cbbe7b436bbd720a82b359dd7580d95eecefa60eaa6a231f35192ecb4d85f35e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/6b/81/05aceabd8b27f724e2c96784016287cc1bfbc349ebfda451de\n",
            "  Building wheel for dash-table (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dash-table: filename=dash_table-5.0.0-py3-none-any.whl size=3911 sha256=d10cb50269b0c264f73a8ae3344e7daa15994979ed96d887b9ce0de25b4dff01\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/5d/4e/7c276b57992951dbe770bf5caad6448d0539c510663aefd2e2\n",
            "  Building wheel for dash-colorscales (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dash-colorscales: filename=dash_colorscales-0.0.4-py3-none-any.whl size=62589 sha256=877b033333f221b60ab0eb00b317258026dbe0d13c2f8e605df05c189d7c1ed7\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/22/7e/183ba2af565e3eb955021fbb4fe8fe4a6b1ed8ae3e5c03236a\n",
            "  Building wheel for dash-daq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dash-daq: filename=dash_daq-0.5.0-py3-none-any.whl size=669716 sha256=b9f43b30ab8fcaa2e8f08b5212ffa72da80066934559fa8f736ff70973932b89\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/54/53/a8d448db5592874db4313240571ca2c069e55f6a6b29bf5847\n",
            "  Building wheel for ppscore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ppscore: filename=ppscore-1.2.0-py2.py3-none-any.whl size=13068 sha256=8c3d6ecebcc875e2dc0266d1bec6bc5508688343fbfecd86e92c3fed8736bd66\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/3c/58/2ff786414b21713edc6f4fdb54fdee89ac37bca5edd1f60634\n",
            "Successfully built dash-core-components dash-html-components dash-table dash-colorscales dash-daq ppscore\n",
            "Installing collected packages: tenacity, brotli, plotly, Flask-Compress, dash-table, dash-html-components, dash-core-components, dash, strsimpy, squarify, ppscore, missingno, lz4, kaleido, flask-ngrok, dash-daq, dash-colorscales, dash-bootstrap-components, dtale\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 4.4.1\n",
            "    Uninstalling plotly-4.4.1:\n",
            "      Successfully uninstalled plotly-4.4.1\n",
            "  Attempting uninstall: missingno\n",
            "    Found existing installation: missingno 0.5.0\n",
            "    Uninstalling missingno-0.5.0:\n",
            "      Successfully uninstalled missingno-0.5.0\n",
            "Successfully installed Flask-Compress-1.10.1 brotli-1.0.9 dash-2.0.0 dash-bootstrap-components-0.13.0 dash-colorscales-0.0.4 dash-core-components-2.0.0 dash-daq-0.5.0 dash-html-components-2.0.0 dash-table-5.0.0 dtale-1.56.0 flask-ngrok-0.0.25 kaleido-0.2.1 lz4-3.1.3 missingno-0.4.2 plotly-5.3.1 ppscore-1.2.0 squarify-0.4.3 strsimpy-0.2.0 tenacity-8.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qX-LUySmiJZv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import dtale\n",
        "#import dtale.app as dtale_app\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from numpy import asarray\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#from kmodes.kmodes import KModes\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQFCE2D_jBF_",
        "outputId": "d6a66db2-53ee-4d93-8aee-6532586cf4b5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfYHFjYWkAHy",
        "outputId": "8eba7a8f-f87e-423b-fa18-aaf3605a7b51"
      },
      "source": [
        "!ls \"/content/drive/My Drive/TFM_Velarte\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'car-causas-agrupadas(v2).ipynb'\t   DF_SEGUN_VELARTE3csv.csv\n",
            "'car-Cleaning_and_Clustering(v6).ipynb'    DF_SEGUN_VELARTE.csv\n",
            "'car-Cleaning_and_Clustering(v7).ipynb'    ETL.ipynb\n",
            " Catboost.ipynb\t\t\t\t   Info\n",
            " catboost.pickle\t\t\t  'Informe Producción y Mermas.xlsx'\n",
            " Cleaning_and_Clustering.ipynb\t\t   Meetings\n",
            "'Cleaning_and_Clustering(v3) (1).ipynb'    NEW.ipynb\n",
            "'Cleaning_and_Clustering(v3).ipynb'\t   OLD\n",
            "'Cleaning_and_Clustering(v4) (1).ipynb'   'Presentación y Memoria'\n",
            "'Cleaning_and_Clustering(v4).ipynb'\t   Report_TFM.gdoc\n",
            "'Copia de causas210918.ipynb'\t\t   VELARTE_MERMA_CAUSAS.csv\n",
            "'Copia de Cleaning_and_Clustering.ipynb'   VELARTE_MERMA_CAUSAS.gsheet\n",
            " Dashboard\t\t\t\t   VELARTE_PROD_MERMA.csv\n",
            " DF_CLEAN_VELARTE.csv\t\t\t   VELARTE_PROD_MERMA.gsheet\n",
            " DF_SEGUN_VELARTE2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CpM3LRRBd5Y"
      },
      "source": [
        "path= '/content/drive/My Drive/TFM_Velarte/DF_CLEAN_VELARTE.csv'\n",
        "delimiter = ','\n",
        "df = pd.read_csv(path, header='infer', delimiter=delimiter)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avFtCB5diJdZ"
      },
      "source": [
        "#dtale_app.USE_NGROK = True\n",
        "path= '/content/drive/My Drive/TFM_Velarte/VELARTE_PROD_MERMA.csv'\n",
        "delimiter = ','\n",
        "df = pd.read_csv(path, header='infer', delimiter=delimiter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8mMDJsqpPY0"
      },
      "source": [
        "dtale_app.USE_NGROK = True\n",
        "path= '/content/drive/My Drive/TFM_Velarte/VELARTE_MERMA_CAUSAS.csv'\n",
        "delimiter = ','\n",
        "df_causa = pd.read_csv(path, header='infer', delimiter=delimiter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6102Xbh9iJgo",
        "outputId": "d877d39d-2295-4e85-d307-62cefb742ba6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Articulo_Orden</th>\n",
              "      <th>Cantidad orden</th>\n",
              "      <th>Cantidad Merma</th>\n",
              "      <th>Cod_ Turno Trabajo</th>\n",
              "      <th>Location Code</th>\n",
              "      <th>Codigo_rechazo</th>\n",
              "      <th>Causa</th>\n",
              "      <th>Weekday</th>\n",
              "      <th>Day</th>\n",
              "      <th>Month</th>\n",
              "      <th>Year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9030101</td>\n",
              "      <td>170.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>372</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9510205</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>372</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9510107</td>\n",
              "      <td>180.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>372</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9510101</td>\n",
              "      <td>288.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>372</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9500302</td>\n",
              "      <td>91.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>372</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Articulo_Orden  Cantidad orden  Cantidad Merma  ...  Day  Month  Year\n",
              "0         9030101           170.0             0.0  ...    3      1  2016\n",
              "1         9510205            80.0             0.0  ...    4      1  2016\n",
              "2         9510107           180.0             0.0  ...    4      1  2016\n",
              "3         9510101           288.0             0.0  ...    4      1  2016\n",
              "4         9500302            91.0             1.1  ...    4      1  2016\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "8I7L_nIHpdjH",
        "outputId": "6206486e-3157-4525-ff41-851e6a7fb68f"
      },
      "source": [
        "df_causa.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c79346dfa0c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_causa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_causa' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Il5-HRXpiJjy",
        "outputId": "a89c1fe6-914a-4c20-a5bc-569ccc8ec7f7"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11601, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J282jqmBiJrI"
      },
      "source": [
        "#TRUNCATE IF DTALE IS NOT ABLE TO OPEN BECAUSE OF ITS SIZE\n",
        "#df_s = df[:150000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaWB8pGFiJve",
        "outputId": "cdcd46cb-5b62-429a-e6ed-a103723f65b6"
      },
      "source": [
        "dtale.show(df_causa)\n",
        "#d.open_browser()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-09-08 18:23:58,346 - INFO     - NumExpr defaulting to 2 threads.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "http://e796-35-201-206-105.ngrok.io/dtale/main/1"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o54BBoiDqeBj"
      },
      "source": [
        "#WE DUPLICATE THE DF TO REMOVE NAN\n",
        "df_copy = df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mD4JRzltmiP"
      },
      "source": [
        "'''df_copy.dropna(subset=['Orden'], how='all', inplace=True)\n",
        "df_copy.dropna(subset=['Fecha'], how='all', inplace=True)\n",
        "df_copy.dropna(subset=['Articulo'], how='all', inplace=True)\n",
        "df_copy.dropna(subset=['Articulo_Orden'], how='all', inplace=True)\n",
        "df_copy.dropna(subset=['Cantidad orden'], how='all', inplace=True)\n",
        "df_copy.dropna(subset=['Resp_ Grupo'], how='all', inplace=True)\n",
        "df_copy.dropna(subset=['Nombre resp_ grup_'], how='all', inplace=True)\n",
        "df_copy.dropna(subset=['Cod_ Turno Trabajo'], how='all', inplace=True)\n",
        "df_copy.dropna(subset=['TIPO'], how='all', inplace=True)\n",
        "df_copy.dropna(subset=['Location Code'], how='all', inplace=True)'''\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "oJUN-pbjspI-",
        "outputId": "cb26d053-4ddb-47b8-fba2-61c01de45e65"
      },
      "source": [
        "#Exploramos los datos\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Articulo_Orden</th>\n",
              "      <th>Cantidad orden</th>\n",
              "      <th>Cantidad Merma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4.180800e+04</td>\n",
              "      <td>41808.000000</td>\n",
              "      <td>41808.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>9.116511e+06</td>\n",
              "      <td>230.712089</td>\n",
              "      <td>15.184632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.837668e+05</td>\n",
              "      <td>253.989526</td>\n",
              "      <td>31.545107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>9.010105e+06</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-15.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>9.010572e+06</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9.050270e+06</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.050542e+06</td>\n",
              "      <td>320.000000</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.520102e+06</td>\n",
              "      <td>2376.000000</td>\n",
              "      <td>1246.343000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Articulo_Orden  Cantidad orden  Cantidad Merma\n",
              "count    4.180800e+04    41808.000000    41808.000000\n",
              "mean     9.116511e+06      230.712089       15.184632\n",
              "std      1.837668e+05      253.989526       31.545107\n",
              "min      9.010105e+06        1.000000      -15.400000\n",
              "25%      9.010572e+06       55.000000        0.000000\n",
              "50%      9.050270e+06      144.000000        0.000000\n",
              "75%      9.050542e+06      320.000000       20.000000\n",
              "max      9.520102e+06     2376.000000     1246.343000"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFa1CgXyt-6r",
        "outputId": "358c8c0f-7073-452e-d506-360d2b1fd9d7"
      },
      "source": [
        "#Exploramos los datos\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 26474 entries, 0 to 26473\n",
            "Data columns (total 12 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   Articulo_Orden      26474 non-null  int64  \n",
            " 1   Cantidad orden      26474 non-null  float64\n",
            " 2   Cantidad Merma      26474 non-null  float64\n",
            " 3   Cod_ Turno Trabajo  26474 non-null  int64  \n",
            " 4   Location Code       26474 non-null  int64  \n",
            " 5   Codigo_rechazo      26474 non-null  int64  \n",
            " 6   Causa               26474 non-null  int64  \n",
            " 7   Weekday             26474 non-null  int64  \n",
            " 8   Day                 26474 non-null  int64  \n",
            " 9   Month               26474 non-null  int64  \n",
            " 10  Year                26474 non-null  int64  \n",
            " 11  Merma_dummy         26474 non-null  int64  \n",
            "dtypes: float64(2), int64(10)\n",
            "memory usage: 2.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqhGDRQbu-AS"
      },
      "source": [
        "from scipy import stats\n",
        "import pandas as pd \n",
        "import multiprocessing\n",
        "import random\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import timeit"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "IFw3-dQTvGmK",
        "outputId": "c859a26f-0710-414e-8060-2097c604d99b"
      },
      "source": [
        "df1 = df[[\"Cantidad orden\",\"Cantidad Merma\",\"Cod_ Turno Trabajo\", \"Location Code\", \"Codigo_rechazo\",\t\"Causa\",\t\"Weekday\",\t\"Day\",\t\"Month\",\t\"Year\"]]\n",
        "df1.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cantidad orden</th>\n",
              "      <th>Cantidad Merma</th>\n",
              "      <th>Cod_ Turno Trabajo</th>\n",
              "      <th>Location Code</th>\n",
              "      <th>Codigo_rechazo</th>\n",
              "      <th>Causa</th>\n",
              "      <th>Weekday</th>\n",
              "      <th>Day</th>\n",
              "      <th>Month</th>\n",
              "      <th>Year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>170.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>372</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>372</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>180.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>372</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>288.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>372</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>372</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Cantidad orden  Cantidad Merma  Cod_ Turno Trabajo  ...  Day  Month  Year\n",
              "0           170.0             0.0                   3  ...    3      1  2016\n",
              "1            80.0             0.0                   3  ...    4      1  2016\n",
              "2           180.0             0.0                   3  ...    4      1  2016\n",
              "3           288.0             0.0                   3  ...    4      1  2016\n",
              "4            91.0             1.1                   2  ...    4      1  2016\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pyx3FkTzLrw"
      },
      "source": [
        "df1=df1.dropna()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Td38RR1ylXL"
      },
      "source": [
        "OHE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8yP3Kz0yLDU"
      },
      "source": [
        "categorical_vars = [\"Cod_ Turno Trabajo\", \"Location Code\", \"Codigo_rechazo\",\t\"Causa\",\t\"Weekday\",\t\"Day\",\t\"Month\",\t\"Year\"]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_-jh_JEyh26"
      },
      "source": [
        "numerical_vars = list(set(df1.columns) - set(categorical_vars))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBVBuzXZywk6",
        "outputId": "49e7e6a4-8a48-43a1-959b-d7cfbcbb14fc"
      },
      "source": [
        "print(categorical_vars)\n",
        "print(numerical_vars)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Cod_ Turno Trabajo', 'Location Code', 'Codigo_rechazo', 'Causa', 'Weekday', 'Day', 'Month', 'Year']\n",
            "['Cantidad orden', 'Cantidad Merma']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ild1b1-DywiS"
      },
      "source": [
        "ohe = OneHotEncoder(sparse = False)\n",
        "ohe_fit = ohe.fit(df1[categorical_vars])\n",
        "X_ohe = pd.DataFrame(ohe.fit_transform(df1[categorical_vars]))\n",
        "X_ohe.columns = pd.DataFrame(ohe_fit.get_feature_names())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY5wfizQywbt"
      },
      "source": [
        "#Volvemos a pegar las variables numéricas.\n",
        "df1 = pd.concat((X_ohe, df1[numerical_vars].reset_index()), axis=1)\n",
        "del df1['index']"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "Gd5LSOoPzzwe",
        "outputId": "96b9cea1-971d-4213-e2f8-5625420f1e28"
      },
      "source": [
        "df1.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>(x0_1,)</th>\n",
              "      <th>(x0_2,)</th>\n",
              "      <th>(x0_3,)</th>\n",
              "      <th>(x1_1,)</th>\n",
              "      <th>(x1_2,)</th>\n",
              "      <th>(x2_31,)</th>\n",
              "      <th>(x2_32,)</th>\n",
              "      <th>(x2_35,)</th>\n",
              "      <th>(x2_71,)</th>\n",
              "      <th>(x2_81,)</th>\n",
              "      <th>(x2_372,)</th>\n",
              "      <th>(x3_1,)</th>\n",
              "      <th>(x3_2,)</th>\n",
              "      <th>(x3_3,)</th>\n",
              "      <th>(x3_4,)</th>\n",
              "      <th>(x4_0,)</th>\n",
              "      <th>(x4_1,)</th>\n",
              "      <th>(x4_2,)</th>\n",
              "      <th>(x4_3,)</th>\n",
              "      <th>(x4_4,)</th>\n",
              "      <th>(x4_5,)</th>\n",
              "      <th>(x4_6,)</th>\n",
              "      <th>(x5_1,)</th>\n",
              "      <th>(x5_2,)</th>\n",
              "      <th>(x5_3,)</th>\n",
              "      <th>(x5_4,)</th>\n",
              "      <th>(x5_5,)</th>\n",
              "      <th>(x5_6,)</th>\n",
              "      <th>(x5_7,)</th>\n",
              "      <th>(x5_8,)</th>\n",
              "      <th>(x5_9,)</th>\n",
              "      <th>(x5_10,)</th>\n",
              "      <th>(x5_11,)</th>\n",
              "      <th>(x5_12,)</th>\n",
              "      <th>(x5_13,)</th>\n",
              "      <th>(x5_14,)</th>\n",
              "      <th>(x5_15,)</th>\n",
              "      <th>(x5_16,)</th>\n",
              "      <th>(x5_17,)</th>\n",
              "      <th>(x5_18,)</th>\n",
              "      <th>(x5_19,)</th>\n",
              "      <th>(x5_20,)</th>\n",
              "      <th>(x5_21,)</th>\n",
              "      <th>(x5_22,)</th>\n",
              "      <th>(x5_23,)</th>\n",
              "      <th>(x5_24,)</th>\n",
              "      <th>(x5_25,)</th>\n",
              "      <th>(x5_26,)</th>\n",
              "      <th>(x5_27,)</th>\n",
              "      <th>(x5_28,)</th>\n",
              "      <th>(x5_29,)</th>\n",
              "      <th>(x5_30,)</th>\n",
              "      <th>(x5_31,)</th>\n",
              "      <th>(x6_1,)</th>\n",
              "      <th>(x6_2,)</th>\n",
              "      <th>(x6_3,)</th>\n",
              "      <th>(x6_4,)</th>\n",
              "      <th>(x6_5,)</th>\n",
              "      <th>(x6_6,)</th>\n",
              "      <th>(x7_2016,)</th>\n",
              "      <th>(x7_2017,)</th>\n",
              "      <th>(x7_2018,)</th>\n",
              "      <th>(x7_2019,)</th>\n",
              "      <th>Cantidad orden</th>\n",
              "      <th>Cantidad Merma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>170.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>1.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   (x0_1,)  (x0_2,)  (x0_3,)  ...  (x7_2019,)  Cantidad orden  Cantidad Merma\n",
              "0      0.0      0.0      1.0  ...         0.0           170.0             0.0\n",
              "1      0.0      0.0      1.0  ...         0.0            80.0             0.0\n",
              "2      0.0      0.0      1.0  ...         0.0           180.0             0.0\n",
              "3      0.0      0.0      1.0  ...         0.0           288.0             0.0\n",
              "4      0.0      1.0      0.0  ...         0.0            91.0             1.1\n",
              "\n",
              "[5 rows x 65 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iaMZkzZ15n-"
      },
      "source": [
        "#TIPIFICAMOS\n",
        "datos_scale = pd.DataFrame(scale(df1))\n",
        "datos_scale.columns = df1.columns\n",
        "datos=datos_scale\n",
        "y = datos['Cantidad Merma']"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqwR5Zop2mDh"
      },
      "source": [
        "#Split en Train/Validación/Test\n",
        "perc_values = [0.7, 0.15, 0.15];\n",
        "y = datos['Cantidad Merma']\n",
        "X = datos.loc[:, datos.columns != 'Cantidad Merma']"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4H4TUKR3PQF"
      },
      "source": [
        "#Creamos los conjuntos de train, validacion y test con el tamaño seleccionado pero respetando el eje temporal.\n",
        "\n",
        "# dimensiones de los conjuntos de train y test\n",
        "n_train = int(X.shape[0] * perc_values[0])\n",
        "n_val = int(X.shape[0] * perc_values[1])\n",
        "n_test = int(X.shape[0] * perc_values[2])\n",
        "\n",
        "# selección del conjunto de train\n",
        "X_train = X.iloc[:n_train]\n",
        "y_train = y.iloc[:n_train]\n",
        "\n",
        "# selección del conjunto de validación\n",
        "X_val = X.iloc[(n_train):(n_train+n_val)]\n",
        "y_val = y.iloc[(n_train):(n_train+n_val)]\n",
        "\n",
        "# selección del conjunto de test\n",
        "X_test = X.iloc[(n_train+n_val):]\n",
        "y_test = y.iloc[(n_train+n_val):]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPYpobUG3iAQ",
        "outputId": "6647a6ae-c427-4362-d16c-361ad69eda8c"
      },
      "source": [
        "#Visualizamos el tamaño de los 3 subdatasets\n",
        "print('Train data size = ' + str(X_train.shape))\n",
        "print('Train target size = ' + str(y_train.shape))\n",
        "print('Validation data size = ' + str(X_val.shape))\n",
        "print('Validation target size = ' + str(y_val.shape))\n",
        "print('Test data size = ' + str(X_test.shape))\n",
        "print('Test target size = ' + str(y_test.shape))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data size = (8120, 64)\n",
            "Train target size = (8120,)\n",
            "Validation data size = (1740, 64)\n",
            "Validation target size = (1740,)\n",
            "Test data size = (1741, 64)\n",
            "Test target size = (1741,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQeOEJDR3zrQ"
      },
      "source": [
        "#GRIDSEARCH\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor  \n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "#Importamos la métrica\n",
        "from sklearn.metrics import mean_absolute_error as metric\n",
        "from sklearn.metrics import r2_score as metric2"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFyIryp24SJj"
      },
      "source": [
        "random_state = 1;\n",
        "nthread = multiprocessing.cpu_count() - 1;"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxfYMtLH4e9X"
      },
      "source": [
        "#Definimos el grid a llevar a cabo\n",
        "\n",
        "# Regresion Logística\n",
        "reg_values = [1e-05, 1e-04, 1e-03, 1e-02,1e-01,1e-00,1e01]\n",
        "\n",
        "# SVM\n",
        "C_values = [0.1, 1, 100];\n",
        "gamma_svm_values = [0.01, 0.1, 1];\n",
        "epsilon_values = [1, 0.1];\n",
        "\n",
        "# Arbol de Decision\n",
        "max_depth_values = [None, 6, 20];\n",
        "min_samples_split_values = [2, 5, 20];\n",
        "min_samples_leaf_values = [1, 5, 20];\n",
        "max_features_values = [None, 1, 2];\n",
        "\n",
        "# Random Forest\n",
        "ntree_values = [10, 100, 1000];\n",
        "\n",
        "# Xgboost\n",
        "nrounds_values = [100]\n",
        "eta_values = [0.99]\n",
        "gamma_values = [ 1]\n",
        "max_depth_values = [20]\n",
        "min_child_weight_values = [20]\n",
        "subsample_values = [0.1]\n",
        "colsample_bytree_values = [0.1]\n",
        "num_parallel_tree_values = [20]\n",
        "lambda_values = [0, 1]\n",
        "alpha_values = [0, 1]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSY_K67T4po9"
      },
      "source": [
        "params_values = [{'model': 'linear regression',\n",
        "                  'regularization': alpha_values},\n",
        "                 {'model': 'svm',\n",
        "                  'C': C_values,\n",
        "                 'gamma': gamma_svm_values,\n",
        "                 'epsilon': epsilon_values},\n",
        "                 {'model': 'decision tree',\n",
        "                  'max_depth': max_depth_values,\n",
        "                 'min_samples_split': min_samples_split_values,\n",
        "                 'min_samples_leaf': min_samples_leaf_values,\n",
        "                 'max_features': max_features_values},\n",
        "                 {'model': 'random forest',\n",
        "                  'n_trees': ntree_values,\n",
        "                 'min_samples_leaf': min_samples_leaf_values,\n",
        "                'min_samples_split': min_samples_split_values,\n",
        "                 'max_features': max_features_values,\n",
        "                 'max_depth': max_depth_values},\n",
        "                 {'model': 'xgboost',\n",
        "                  'nrounds': nrounds_values,\n",
        "                  'eta': eta_values,\n",
        "                 'gamma': gamma_values,\n",
        "                 'max_depth': max_depth_values,\n",
        "                 'min_child_weight': min_child_weight_values,\n",
        "                 'subsample': subsample_values,\n",
        "                 'colsample_bytree': colsample_bytree_values,\n",
        "                 'num_parallel_tree': num_parallel_tree_values,\n",
        "                 'lambda': lambda_values,\n",
        "                 'alpha': alpha_values}]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwFvDOnQ4qls",
        "outputId": "b9665ac5-52ec-46f8-b886-7a5328b926ff"
      },
      "source": [
        "params_values"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'model': 'linear regression', 'regularization': [0, 1]},\n",
              " {'C': [0.1, 1, 100],\n",
              "  'epsilon': [1, 0.1],\n",
              "  'gamma': [0.01, 0.1, 1],\n",
              "  'model': 'svm'},\n",
              " {'max_depth': [20],\n",
              "  'max_features': [None, 1, 2],\n",
              "  'min_samples_leaf': [1, 5, 20],\n",
              "  'min_samples_split': [2, 5, 20],\n",
              "  'model': 'decision tree'},\n",
              " {'max_depth': [20],\n",
              "  'max_features': [None, 1, 2],\n",
              "  'min_samples_leaf': [1, 5, 20],\n",
              "  'min_samples_split': [2, 5, 20],\n",
              "  'model': 'random forest',\n",
              "  'n_trees': [10, 100, 1000]},\n",
              " {'alpha': [0, 1],\n",
              "  'colsample_bytree': [0.1],\n",
              "  'eta': [0.99],\n",
              "  'gamma': [1],\n",
              "  'lambda': [0, 1],\n",
              "  'max_depth': [20],\n",
              "  'min_child_weight': [20],\n",
              "  'model': 'xgboost',\n",
              "  'nrounds': [100],\n",
              "  'num_parallel_tree': [20],\n",
              "  'subsample': [0.1]}]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9EieQN745vx",
        "outputId": "807a23ca-7c8c-4582-999c-3893eaa11880"
      },
      "source": [
        "total_iteraciones = 0\n",
        "for params in params_values:\n",
        "    if params['model'] == 'linear regression':\n",
        "        n = len(params['regularization'])\n",
        "    elif params['model'] == 'svm':\n",
        "        n = len(params['C'])*len(params['gamma'])*len(params['epsilon'])\n",
        "    elif params['model'] == 'decision tree':\n",
        "        n = len(params['max_depth'])*len(params['min_samples_split'])*len(params['min_samples_leaf'])*len(params['max_features'])\n",
        "    elif params['model'] == 'random forest':\n",
        "        n = len(params['n_trees'])*len(params['min_samples_leaf'])*len(params['max_features'])*len(params['max_depth'])*len(params['min_samples_split'])\n",
        "    elif params['model'] == 'xgboost':\n",
        "        n = len(params['nrounds'])*len(params['eta'])*len(params['gamma'])*len(params['max_depth'])*len(params['min_child_weight'])*len(params['subsample'])*len(params['colsample_bytree'])*len(params['num_parallel_tree'])*len(params['lambda'])*len(params['alpha'])\n",
        "    total_iteraciones = total_iteraciones + n;\n",
        "    print(str(n)+ ' iteraciones de ' + str(params['model']))\n",
        "print(str(total_iteraciones)+ ' iteraciones en total')   "
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 iteraciones de linear regression\n",
            "18 iteraciones de svm\n",
            "27 iteraciones de decision tree\n",
            "81 iteraciones de random forest\n",
            "4 iteraciones de xgboost\n",
            "132 iteraciones en total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9kB7aSSoOP4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcjwBaMdoO56",
        "outputId": "2eabbc14-8f68-4034-c607-ff082337cb41"
      },
      "source": [
        "grid_results = pd.DataFrame();\n",
        "num_iter = 0\n",
        "for params in params_values:\n",
        "    \n",
        "        # Linear Regression\n",
        "    if params['model'] == 'linear regression':\n",
        "        for regularization in params['regularization']:\n",
        "            # Actualizar contador\n",
        "            num_iter += 1; \n",
        "                \n",
        "            # print control iteracion modelo\n",
        "            print('Inicio de iteracion ' + str(num_iter) + \n",
        "                '. Regularizacion = ' + str(regularization) + \n",
        "                '\\n')\n",
        "                \n",
        "           \n",
        "            model = Ridge(alpha = regularization, random_state = random_state)\n",
        "    \n",
        "               \n",
        "            model.fit(X_train, np.array(y_train))\n",
        "\n",
        "            # Generar predicciones\n",
        "            pred_train = model.predict(X_train)\n",
        "            pred_val = model.predict(X_val)\n",
        "\n",
        "            # Calcular métricas de evaluación\n",
        "            error_train = metric2(y_train, pred_train)    \n",
        "            error_val = metric2(y_val, pred_val)                                           \n",
        "\n",
        "            print('Fin de iteracion ' + str(num_iter) + \n",
        "                     '. Regularizacion = ' + str(regularization) + \n",
        "                      '. Error train = '  + str(error_train) + \n",
        "                      ' -  Error val = '  + str(error_val)  + \n",
        "                      '\\n')\n",
        "            grid_results = grid_results.append(pd.DataFrame(data={'model':'Linear Regression',\n",
        "                                                                      'params': [{'regularization':[regularization]}],\n",
        "                                                                                          'error_train':[error_train],\n",
        "                                                                                          'error_val':[error_val]},\n",
        "                                                                                           columns=['model', 'params','error_train', 'error_val']),\n",
        "                                                   ignore_index=True)\n",
        "     \n",
        "    # SVM\n",
        "    if params['model'] == 'svm':\n",
        "        for C in params['C']:\n",
        "            for gamma in params['gamma']:  \n",
        "                for epsilon in params['epsilon']:  \n",
        "                    # Actualizar contador\n",
        "                    num_iter += 1; \n",
        "\n",
        "                    # print control iteracion modelo\n",
        "                    print('Inicio de iteracion ' + str(num_iter) + \n",
        "                          '. C = ' + str(C) + \n",
        "                          ', gamma = '  + str(gamma) +\n",
        "                          ', epsilon = '  + str(epsilon) +\n",
        "                          '\\n')\n",
        "\n",
        "                    # Entrenar modelo               \n",
        "                    model = SVR(C = C, gamma = gamma, epsilon=epsilon)\n",
        "               \n",
        "                    model.fit(X_train, np.array(y_train))\n",
        "\n",
        "                    # Generar predicciones\n",
        "                    pred_train = model.predict(X_train)\n",
        "                    pred_val = model.predict(X_val)\n",
        "\n",
        "                    # Calcular métricas de evaluación\n",
        "                    error_train = metric2(y_train, pred_train)    \n",
        "                    error_val = metric2(y_val, pred_val)                                          \n",
        "\n",
        "                    print('Fin de iteracion ' + str(num_iter) + \n",
        "                         '. C = ' + str(C) + \n",
        "                          ', gamma = '  + str(gamma) +\n",
        "                          ' -  error train = '  + str(error_train) + \n",
        "                          ' -  error val = '  + str(error_val)  + \n",
        "                          '\\n')\n",
        "                    grid_results = grid_results.append(pd.DataFrame(data={'model':'SVM',\n",
        "                                                                         'params': [{'C':[C],\n",
        "                                                                                  'gamma':[gamma],\n",
        "                                                                                    'epsilon': [epsilon]}],\n",
        "                                                                                          'error_train':[error_train],\n",
        "                                                                                          'error_val':[error_val]},\n",
        "                                                                                           columns=['model', 'params','error_train', 'error_val']),\n",
        "                                                       ignore_index=True)\n",
        "                \n",
        "    # Decision Tree\n",
        "    if params['model'] == 'decision tree':\n",
        "        for max_depth in params['max_depth']:\n",
        "            for min_samples_split in params['min_samples_split']:  \n",
        "                for min_samples_leaf in params['min_samples_leaf']:  \n",
        "                    for max_features in params['max_features']:  \n",
        "                \n",
        "                        # Actualizar contador\n",
        "                        num_iter += 1; \n",
        "\n",
        "                        # print control iteracion modelo\n",
        "                        print('Inicio de iteracion ' + str(num_iter) + \n",
        "                              '. max_depth = ' + str(max_depth) + \n",
        "                              ', min_samples_split = '  + str(min_samples_split) +\n",
        "                              ', min_samples_leaf = '  + str(min_samples_leaf) +\n",
        "                              ', max_features = '  + str(max_features) +\n",
        "                              '\\n')\n",
        "\n",
        "                        # Entrenar modelo               \n",
        "                        model = DecisionTreeRegressor(max_depth = max_depth,\n",
        "                                                      min_samples_split = min_samples_split,\n",
        "                                                      min_samples_leaf = min_samples_leaf,\n",
        "                                                      max_features = max_features, random_state = random_state)\n",
        "\n",
        "                        model.fit(X_train, np.array(y_train))\n",
        "\n",
        "                        model.fit(X_train, np.array(y_train))\n",
        "\n",
        "                        # Generar predicciones\n",
        "                        pred_train = model.predict(X_train)\n",
        "                        pred_val = model.predict(X_val)\n",
        "\n",
        "                        # Calcular métricas de evaluación\n",
        "                        error_train = metric2(y_train, pred_train)    \n",
        "                        error_val = metric2(y_val, pred_val)  \n",
        "\n",
        "                        print('Fin de iteracion ' + str(num_iter) + \n",
        "                             '. max_depth = ' + str(max_depth) + \n",
        "                              ', min_samples_split = '  + str(min_samples_split) +\n",
        "                              ', min_samples_leaf = '  + str(min_samples_leaf) +\n",
        "                              ', max_features = '  + str(max_features) +\n",
        "                              ' -  error train = '  + str(error_train) + \n",
        "                              ' -  error val = '  + str(error_val)  + \n",
        "                              '\\n')\n",
        "                        grid_results = grid_results.append(pd.DataFrame(data={'model':'decision tree',\n",
        "                                                                              'params': [{'max_depth':[max_depth],\n",
        "                                                                                          'min_samples_split':[min_samples_split],\n",
        "                                                                                          'min_samples_leaf':[min_samples_leaf],\n",
        "                                                                                          'max_features':[max_features]}],\n",
        "                                                                                          'error_train':[error_train],\n",
        "                                                                                          'error_val':[error_val]},\n",
        "                                                                                           columns=['model', 'params','error_train', 'error_val']),\n",
        "                                                           ignore_index=True)  \n",
        "                        \n",
        "    \n",
        "    # Random Forest\n",
        "    if params['model'] == 'random forest':\n",
        "        for n_trees in params['n_trees']:\n",
        "            for max_depth in params['max_depth']:\n",
        "                for min_samples_split in params['min_samples_split']:  \n",
        "                    for min_samples_leaf in params['min_samples_leaf']:  \n",
        "                        for max_features in params['max_features']:  \n",
        "                \n",
        "                            # Actualizar contador\n",
        "                            num_iter += 1; \n",
        "\n",
        "                            # print control iteracion modelo\n",
        "                            print('Inicio de iteracion ' + str(num_iter) + \n",
        "                                  '. n_trees = ' + str(n_trees) + \n",
        "                                  ', max_depth = ' + str(max_depth) + \n",
        "                                  ', min_samples_split = '  + str(min_samples_split) +\n",
        "                                  ', min_samples_leaf = '  + str(min_samples_leaf) +\n",
        "                                  ', max_features = '  + str(max_features) +\n",
        "                                  '\\n')\n",
        "\n",
        "                            # Entrenar modelo               \n",
        "                            model = RandomForestRegressor(n_estimators = n_trees,\n",
        "                                                          max_depth = max_depth,\n",
        "                                                          min_samples_split = min_samples_split,\n",
        "                                                          min_samples_leaf = min_samples_leaf,\n",
        "                                                          max_features = max_features, random_state = random_state)\n",
        "\n",
        "                            model.fit(X_train, np.array(y_train))\n",
        "\n",
        "                            # Generar predicciones\n",
        "                            pred_train = model.predict(X_train)\n",
        "                            pred_val = model.predict(X_val)\n",
        "\n",
        "                            # Calcular métricas de evaluación\n",
        "                            error_train = metric2(y_train, pred_train)    \n",
        "                            error_val = metric2(y_val, pred_val)                                         \n",
        "\n",
        "                            print('Fin de iteracion ' + str(num_iter) + \n",
        "                                 '. n_trees = ' + str(n_trees) + \n",
        "                                  ', max_depth = ' + str(max_depth) + \n",
        "                                  ', min_samples_split = '  + str(min_samples_split) +\n",
        "                                  ', min_samples_leaf = '  + str(min_samples_leaf) +\n",
        "                                  ', max_features = '  + str(max_features) +\n",
        "                                  ' -  error train = '  + str(error_train) + \n",
        "                                  ' -  error val = '  + str(error_val)  + \n",
        "                                  '\\n')\n",
        "                            grid_results = grid_results.append(pd.DataFrame(data={'model':'random forest',\n",
        "                                                                                  'params': [{'n_trees':[n_trees],\n",
        "                                                                                              'max_depth':[max_depth],\n",
        "                                                                                              'min_samples_split':[min_samples_split],\n",
        "                                                                                              'min_samples_leaf':[min_samples_leaf],\n",
        "                                                                                              'max_features':[max_features]}],\n",
        "                                                                                          'error_train':[error_train],\n",
        "                                                                                          'error_val':[error_val]},\n",
        "                                                                                           columns=['model', 'params','error_train', 'error_val']),\n",
        "                                                               ignore_index=True)  \n",
        "    \n",
        "    # XGBOOST\n",
        "    if params['model'] == 'xgboost':\n",
        "        for nrounds in params['nrounds']:\n",
        "            for eta in params['eta']:\n",
        "                for gamma in params['gamma']:\n",
        "                    for max_depth in params['max_depth']:\n",
        "                        for min_child_weight in params['min_child_weight']:\n",
        "                            for subsample in params['subsample']:\n",
        "                                for colsample_bytree in params['colsample_bytree']:\n",
        "                                    for num_parallel_tree in params['num_parallel_tree']:\n",
        "                                        for lamda in params['lambda']:\n",
        "                                            for alpha in params['alpha']:\n",
        "\n",
        "                                                # Actualizar contador\n",
        "                                                num_iter += 1; \n",
        "\n",
        "                                                # print control iteracion modelo\n",
        "                                                print('Inicio de iteracion ' + str(num_iter) +\n",
        "                                                      '. Parametro nrounds = ' + str(nrounds) +\n",
        "                                                      ', parametro eta = ' + str(eta) + \n",
        "                                                      ', parametro gamma = '  + str(gamma) +\n",
        "                                                      ', parametro max_depth = '  + str(max_depth) +\n",
        "                                                      ', parametro min_child_weight = '  + str(min_child_weight) +\n",
        "                                                      ', parametro subsample = '  + str(subsample) +\n",
        "                                                      ', parametro colsample_bytree = '  + str(colsample_bytree) +\n",
        "                                                      ', parametro num_parallel_tree = '  + str(num_parallel_tree) +\n",
        "                                                      ', parametro lambda = '  + str(lamda) +\n",
        "                                                      ', parametro alpha = '  + str(alpha) + \n",
        "                                                      '\\n')\n",
        "                                                # Entrenar modelo\n",
        "                                                model = XGBRegressor(nthread = nthread,\n",
        "                                                                      random_state = random_state,\n",
        "                                                                      n_estimators = nrounds, \n",
        "                                                                      learning_rate = eta, \n",
        "                                                                      gamma = gamma,\n",
        "                                                                      max_depth = max_depth,\n",
        "                                                                      min_child_weight = min_child_weight ,\n",
        "                                                                      subsample = subsample,\n",
        "                                                                      colsample_bytree = colsample_bytree,\n",
        "                                                                      num_parallel_tree  = num_parallel_tree,\n",
        "                                                                      reg_lambda = lamda,\n",
        "                                                                      reg_alpha = alpha)\n",
        "                                                model.fit(X_train, np.array(y_train))\n",
        "\n",
        "                                                # Generar predicciones\n",
        "                                                pred_train = model.predict(X_train)\n",
        "                                                pred_val = model.predict(X_val)\n",
        "\n",
        "                                                # Calcular métricas de evaluación\n",
        "                                                error_train = metric2(y_train, pred_train)    \n",
        "                                                error_val = metric2(y_val, pred_val)                                            \n",
        "\n",
        "                                                print('Fin de iteracion ' + str(num_iter) + \n",
        "                                                      '. Parametro nrounds = ' + str(nrounds) + \n",
        "                                                      ', parametro eta = ' + str(eta) + \n",
        "                                                      ', parametro gamma = '  + str(gamma) +\n",
        "                                                      ', parametro max_depth = '  + str(max_depth) +\n",
        "                                                      ', parametro min_child_weight = '  + str(min_child_weight) +\n",
        "                                                      ', parametro subsample = '  + str(subsample) +\n",
        "                                                      ', parametro colsample_bytree = '  + str(colsample_bytree) +\n",
        "                                                      ', parametro num_parallel_tree = '  + str(num_parallel_tree) +\n",
        "                                                      ', parametro lambda = '  + str(lamda) +\n",
        "                                                      ', parametro alpha = '  + str(alpha) + \n",
        "                                                      ' -  error train = '  + str(error_train) + \n",
        "                                                      ' -  error val = '  + str(error_val)  + \n",
        "                                                      '\\n')\n",
        "                                                grid_results = grid_results.append(pd.DataFrame(data={'model':'xgboost',\n",
        "                                                                                              'params': [{'nrounds':[nrounds],\n",
        "                                                                                              'eta':[eta],\n",
        "                                                                                              'gamma':[gamma],\n",
        "                                                                                              'max_depth':[max_depth],\n",
        "                                                                                              'min_child_weight':[min_child_weight],\n",
        "                                                                                              'subsample':[subsample],\n",
        "                                                                                              'colsample_bytree':[colsample_bytree],\n",
        "                                                                                              'num_parallel_tree':[num_parallel_tree],\n",
        "                                                                                              'lamda':[lamda],\n",
        "                                                                                              'alpha':[alpha]}],\n",
        "                                                                                              'error_train':[error_train],\n",
        "                                                                                              'error_val':[error_val]},\n",
        "                                                                                               columns=['model', 'params','error_train', 'error_val']), \n",
        "                                                                                   ignore_index=True)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicio de iteracion 1. Regularizacion = 0\n",
            "\n",
            "Fin de iteracion 1. Regularizacion = 0. Error train = 0.6587860883838235 -  Error val = -2.60536164161348e+25\n",
            "\n",
            "Inicio de iteracion 2. Regularizacion = 1\n",
            "\n",
            "Fin de iteracion 2. Regularizacion = 1. Error train = 0.6600750425348687 -  Error val = 0.5533241233229091\n",
            "\n",
            "Inicio de iteracion 3. C = 0.1, gamma = 0.01, epsilon = 1\n",
            "\n",
            "Fin de iteracion 3. C = 0.1, gamma = 0.01 -  error train = -0.8691945782979789 -  error val = 0.021866877758647707\n",
            "\n",
            "Inicio de iteracion 4. C = 0.1, gamma = 0.01, epsilon = 0.1\n",
            "\n",
            "Fin de iteracion 4. C = 0.1, gamma = 0.01 -  error train = 0.6331190473997335 -  error val = 0.4762386723845572\n",
            "\n",
            "Inicio de iteracion 5. C = 0.1, gamma = 0.1, epsilon = 1\n",
            "\n",
            "Fin de iteracion 5. C = 0.1, gamma = 0.1 -  error train = -1.1202373065862101 -  error val = -0.21867791681361703\n",
            "\n",
            "Inicio de iteracion 6. C = 0.1, gamma = 0.1, epsilon = 0.1\n",
            "\n",
            "Fin de iteracion 6. C = 0.1, gamma = 0.1 -  error train = 0.14526839958777638 -  error val = -0.013813901790022287\n",
            "\n",
            "Inicio de iteracion 7. C = 0.1, gamma = 1, epsilon = 1\n",
            "\n",
            "Fin de iteracion 7. C = 0.1, gamma = 1 -  error train = -1.1382543824642295 -  error val = -0.21261878641148235\n",
            "\n",
            "Inicio de iteracion 8. C = 0.1, gamma = 1, epsilon = 0.1\n",
            "\n",
            "Fin de iteracion 8. C = 0.1, gamma = 1 -  error train = 0.06663859382805493 -  error val = -0.052699191922331856\n",
            "\n",
            "Inicio de iteracion 9. C = 1, gamma = 0.01, epsilon = 1\n",
            "\n",
            "Fin de iteracion 9. C = 1, gamma = 0.01 -  error train = -0.13090505107860118 -  error val = 0.24423675047655946\n",
            "\n",
            "Inicio de iteracion 10. C = 1, gamma = 0.01, epsilon = 0.1\n",
            "\n",
            "Fin de iteracion 10. C = 1, gamma = 0.01 -  error train = 0.710135600460032 -  error val = 0.4948949277350504\n",
            "\n",
            "Inicio de iteracion 11. C = 1, gamma = 0.1, epsilon = 1\n",
            "\n",
            "Fin de iteracion 11. C = 1, gamma = 0.1 -  error train = -0.9192264670794672 -  error val = -0.28917388658997645\n",
            "\n",
            "Inicio de iteracion 12. C = 1, gamma = 0.1, epsilon = 0.1\n",
            "\n",
            "Fin de iteracion 12. C = 1, gamma = 0.1 -  error train = 0.7007583958997214 -  error val = 0.10011022455124563\n",
            "\n",
            "Inicio de iteracion 13. C = 1, gamma = 1, epsilon = 1\n",
            "\n",
            "Fin de iteracion 13. C = 1, gamma = 1 -  error train = -0.9637358336844057 -  error val = -0.25613465108934097\n",
            "\n",
            "Inicio de iteracion 14. C = 1, gamma = 1, epsilon = 0.1\n",
            "\n",
            "Fin de iteracion 14. C = 1, gamma = 1 -  error train = 0.5643332887120134 -  error val = -0.004570455397742812\n",
            "\n",
            "Inicio de iteracion 15. C = 100, gamma = 0.01, epsilon = 1\n",
            "\n",
            "Fin de iteracion 15. C = 100, gamma = 0.01 -  error train = 0.5753179641462696 -  error val = 0.40507701533199736\n",
            "\n",
            "Inicio de iteracion 16. C = 100, gamma = 0.01, epsilon = 0.1\n",
            "\n",
            "Fin de iteracion 16. C = 100, gamma = 0.01 -  error train = 0.9598091811736414 -  error val = 0.4815954721473428\n",
            "\n",
            "Inicio de iteracion 17. C = 100, gamma = 0.1, epsilon = 1\n",
            "\n",
            "Fin de iteracion 17. C = 100, gamma = 0.1 -  error train = -0.7111535092441328 -  error val = -0.3603149973799915\n",
            "\n",
            "Inicio de iteracion 18. C = 100, gamma = 0.1, epsilon = 0.1\n",
            "\n",
            "Fin de iteracion 18. C = 100, gamma = 0.1 -  error train = 0.982998734492561 -  error val = 0.09897694346850983\n",
            "\n",
            "Inicio de iteracion 19. C = 100, gamma = 1, epsilon = 1\n",
            "\n",
            "Fin de iteracion 19. C = 100, gamma = 1 -  error train = -0.7348163964996715 -  error val = -0.2988253756619055\n",
            "\n",
            "Inicio de iteracion 20. C = 100, gamma = 1, epsilon = 0.1\n",
            "\n",
            "Fin de iteracion 20. C = 100, gamma = 1 -  error train = 0.9824202525113144 -  error val = -0.002724760903074497\n",
            "\n",
            "Inicio de iteracion 21. max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = None\n",
            "\n",
            "Fin de iteracion 21. max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = None -  error train = 0.9886816240555079 -  error val = 0.4341725708256009\n",
            "\n",
            "Inicio de iteracion 22. max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = 1\n",
            "\n",
            "Fin de iteracion 22. max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = 1 -  error train = 0.868301365624409 -  error val = 0.38986188097305396\n",
            "\n",
            "Inicio de iteracion 23. max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = 2\n",
            "\n",
            "Fin de iteracion 23. max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = 2 -  error train = 0.9142494391040604 -  error val = 0.5072549425317701\n",
            "\n",
            "Inicio de iteracion 24. max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = None\n",
            "\n",
            "Fin de iteracion 24. max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = None -  error train = 0.7744210400731029 -  error val = 0.49596601555663566\n",
            "\n",
            "Inicio de iteracion 25. max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = 1\n",
            "\n",
            "Fin de iteracion 25. max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = 1 -  error train = 0.22567514881848316 -  error val = 0.2550202282798818\n",
            "\n",
            "Inicio de iteracion 26. max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = 2\n",
            "\n",
            "Fin de iteracion 26. max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = 2 -  error train = 0.6121196965530711 -  error val = 0.491573821417973\n",
            "\n",
            "Inicio de iteracion 27. max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = None\n",
            "\n",
            "Fin de iteracion 27. max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = None -  error train = 0.7024892152278908 -  error val = 0.5643474579665072\n",
            "\n",
            "Inicio de iteracion 28. max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = 1\n",
            "\n",
            "Fin de iteracion 28. max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = 1 -  error train = 0.3394204393184228 -  error val = 0.23926730493289194\n",
            "\n",
            "Inicio de iteracion 29. max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = 2\n",
            "\n",
            "Fin de iteracion 29. max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = 2 -  error train = 0.42993810633715646 -  error val = 0.27526371602685507\n",
            "\n",
            "Inicio de iteracion 30. max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = None\n",
            "\n",
            "Fin de iteracion 30. max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = None -  error train = 0.9415126381768096 -  error val = 0.42818660313187795\n",
            "\n",
            "Inicio de iteracion 31. max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = 1\n",
            "\n",
            "Fin de iteracion 31. max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = 1 -  error train = 0.7323215507450934 -  error val = 0.4337342235104219\n",
            "\n",
            "Inicio de iteracion 32. max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = 2\n",
            "\n",
            "Fin de iteracion 32. max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = 2 -  error train = 0.783452717421169 -  error val = 0.43647835629151177\n",
            "\n",
            "Inicio de iteracion 33. max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = None\n",
            "\n",
            "Fin de iteracion 33. max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = None -  error train = 0.7744210400731029 -  error val = 0.49596601555663566\n",
            "\n",
            "Inicio de iteracion 34. max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = 1\n",
            "\n",
            "Fin de iteracion 34. max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = 1 -  error train = 0.22567514881848316 -  error val = 0.2550202282798818\n",
            "\n",
            "Inicio de iteracion 35. max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = 2\n",
            "\n",
            "Fin de iteracion 35. max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = 2 -  error train = 0.6121196965530711 -  error val = 0.491573821417973\n",
            "\n",
            "Inicio de iteracion 36. max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = None\n",
            "\n",
            "Fin de iteracion 36. max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = None -  error train = 0.7024892152278908 -  error val = 0.5643474579665072\n",
            "\n",
            "Inicio de iteracion 37. max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = 1\n",
            "\n",
            "Fin de iteracion 37. max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = 1 -  error train = 0.3394204393184228 -  error val = 0.23926730493289194\n",
            "\n",
            "Inicio de iteracion 38. max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = 2\n",
            "\n",
            "Fin de iteracion 38. max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = 2 -  error train = 0.42993810633715646 -  error val = 0.27526371602685507\n",
            "\n",
            "Inicio de iteracion 39. max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = None\n",
            "\n",
            "Fin de iteracion 39. max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = None -  error train = 0.7709224881567909 -  error val = 0.5234964124811279\n",
            "\n",
            "Inicio de iteracion 40. max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = 1\n",
            "\n",
            "Fin de iteracion 40. max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = 1 -  error train = 0.5240028042985285 -  error val = 0.4058465444620042\n",
            "\n",
            "Inicio de iteracion 41. max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = 2\n",
            "\n",
            "Fin de iteracion 41. max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = 2 -  error train = 0.6610539983927199 -  error val = 0.42623992995202187\n",
            "\n",
            "Inicio de iteracion 42. max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = None\n",
            "\n",
            "Fin de iteracion 42. max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = None -  error train = 0.7325875962856 -  error val = 0.5391295964575233\n",
            "\n",
            "Inicio de iteracion 43. max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = 1\n",
            "\n",
            "Fin de iteracion 43. max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = 1 -  error train = 0.4551313981574071 -  error val = 0.4641763267258491\n",
            "\n",
            "Inicio de iteracion 44. max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = 2\n",
            "\n",
            "Fin de iteracion 44. max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = 2 -  error train = 0.529833145629301 -  error val = 0.38597207820871093\n",
            "\n",
            "Inicio de iteracion 45. max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = None\n",
            "\n",
            "Fin de iteracion 45. max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = None -  error train = 0.7024892152278908 -  error val = 0.5643474579665072\n",
            "\n",
            "Inicio de iteracion 46. max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = 1\n",
            "\n",
            "Fin de iteracion 46. max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = 1 -  error train = 0.3394204393184228 -  error val = 0.23926730493289194\n",
            "\n",
            "Inicio de iteracion 47. max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = 2\n",
            "\n",
            "Fin de iteracion 47. max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = 2 -  error train = 0.42993810633715646 -  error val = 0.27526371602685507\n",
            "\n",
            "Inicio de iteracion 48. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = None\n",
            "\n",
            "Fin de iteracion 48. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = None -  error train = 0.9299583802718091 -  error val = 0.5171026609138676\n",
            "\n",
            "Inicio de iteracion 49. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = 1\n",
            "\n",
            "Fin de iteracion 49. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = 1 -  error train = 0.8736560752619555 -  error val = 0.44907082106287033\n",
            "\n",
            "Inicio de iteracion 50. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = 2\n",
            "\n",
            "Fin de iteracion 50. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = 2 -  error train = 0.9005079410120203 -  error val = 0.5067613598070859\n",
            "\n",
            "Inicio de iteracion 51. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = None\n",
            "\n",
            "Fin de iteracion 51. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = None -  error train = 0.7670456060708896 -  error val = 0.5451830755925668\n",
            "\n",
            "Inicio de iteracion 52. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = 1\n",
            "\n",
            "Fin de iteracion 52. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = 1 -  error train = 0.5674467080937374 -  error val = 0.3958498833189471\n",
            "\n",
            "Inicio de iteracion 53. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = 2\n",
            "\n",
            "Fin de iteracion 53. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = 2 -  error train = 0.6241287201145146 -  error val = 0.4942558089036797\n",
            "\n",
            "Inicio de iteracion 54. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = None\n",
            "\n",
            "Fin de iteracion 54. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = None -  error train = 0.6972085307198796 -  error val = 0.5636371563000311\n",
            "\n",
            "Inicio de iteracion 55. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = 1\n",
            "\n",
            "Fin de iteracion 55. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = 1 -  error train = 0.43435707632692 -  error val = 0.29178690199102686\n",
            "\n",
            "Inicio de iteracion 56. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = 2\n",
            "\n",
            "Fin de iteracion 56. n_trees = 10, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = 2 -  error train = 0.5411382477030184 -  error val = 0.43912790470276375\n",
            "\n",
            "Inicio de iteracion 57. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = None\n",
            "\n",
            "Fin de iteracion 57. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = None -  error train = 0.8893840631078911 -  error val = 0.5043815479177021\n",
            "\n",
            "Inicio de iteracion 58. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = 1\n",
            "\n",
            "Fin de iteracion 58. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = 1 -  error train = 0.7693219687005802 -  error val = 0.45015625323492114\n",
            "\n",
            "Inicio de iteracion 59. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = 2\n",
            "\n",
            "Fin de iteracion 59. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = 2 -  error train = 0.8114995313930251 -  error val = 0.5141388133820051\n",
            "\n",
            "Inicio de iteracion 60. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = None\n",
            "\n",
            "Fin de iteracion 60. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = None -  error train = 0.7670456060708896 -  error val = 0.5451830755925668\n",
            "\n",
            "Inicio de iteracion 61. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = 1\n",
            "\n",
            "Fin de iteracion 61. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = 1 -  error train = 0.5674467080937374 -  error val = 0.3958498833189471\n",
            "\n",
            "Inicio de iteracion 62. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = 2\n",
            "\n",
            "Fin de iteracion 62. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = 2 -  error train = 0.6241287201145146 -  error val = 0.4942558089036797\n",
            "\n",
            "Inicio de iteracion 63. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = None\n",
            "\n",
            "Fin de iteracion 63. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = None -  error train = 0.6972085307198796 -  error val = 0.5636371563000311\n",
            "\n",
            "Inicio de iteracion 64. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = 1\n",
            "\n",
            "Fin de iteracion 64. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = 1 -  error train = 0.43435707632692 -  error val = 0.29178690199102686\n",
            "\n",
            "Inicio de iteracion 65. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = 2\n",
            "\n",
            "Fin de iteracion 65. n_trees = 10, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = 2 -  error train = 0.5411382477030184 -  error val = 0.43912790470276375\n",
            "\n",
            "Inicio de iteracion 66. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = None\n",
            "\n",
            "Fin de iteracion 66. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = None -  error train = 0.7882085899968514 -  error val = 0.5441720967318225\n",
            "\n",
            "Inicio de iteracion 67. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = 1\n",
            "\n",
            "Fin de iteracion 67. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = 1 -  error train = 0.664023466064756 -  error val = 0.46587297372371483\n",
            "\n",
            "Inicio de iteracion 68. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = 2\n",
            "\n",
            "Fin de iteracion 68. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = 2 -  error train = 0.703052004023067 -  error val = 0.510325456486524\n",
            "\n",
            "Inicio de iteracion 69. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = None\n",
            "\n",
            "Fin de iteracion 69. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = None -  error train = 0.7446885137442196 -  error val = 0.546404757096107\n",
            "\n",
            "Inicio de iteracion 70. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = 1\n",
            "\n",
            "Fin de iteracion 70. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = 1 -  error train = 0.5673524291923963 -  error val = 0.4155132417595374\n",
            "\n",
            "Inicio de iteracion 71. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = 2\n",
            "\n",
            "Fin de iteracion 71. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = 2 -  error train = 0.6228268603711953 -  error val = 0.5045817705394766\n",
            "\n",
            "Inicio de iteracion 72. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = None\n",
            "\n",
            "Fin de iteracion 72. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = None -  error train = 0.6972085307198796 -  error val = 0.5636371563000311\n",
            "\n",
            "Inicio de iteracion 73. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = 1\n",
            "\n",
            "Fin de iteracion 73. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = 1 -  error train = 0.43435707632692 -  error val = 0.29178690199102686\n",
            "\n",
            "Inicio de iteracion 74. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = 2\n",
            "\n",
            "Fin de iteracion 74. n_trees = 10, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = 2 -  error train = 0.5411382477030184 -  error val = 0.43912790470276375\n",
            "\n",
            "Inicio de iteracion 75. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = None\n",
            "\n",
            "Fin de iteracion 75. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = None -  error train = 0.9425190679813357 -  error val = 0.5242329155993467\n",
            "\n",
            "Inicio de iteracion 76. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = 1\n",
            "\n",
            "Fin de iteracion 76. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = 1 -  error train = 0.887662535321392 -  error val = 0.49288327843103463\n",
            "\n",
            "Inicio de iteracion 77. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = 2\n",
            "\n",
            "Fin de iteracion 77. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = 2 -  error train = 0.915247829401063 -  error val = 0.525400724538083\n",
            "\n",
            "Inicio de iteracion 78. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = None\n",
            "\n",
            "Fin de iteracion 78. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = None -  error train = 0.7718937184871943 -  error val = 0.5530698786499328\n",
            "\n",
            "Inicio de iteracion 79. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = 1\n",
            "\n",
            "Fin de iteracion 79. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = 1 -  error train = 0.5882862266511687 -  error val = 0.43127025585532375\n",
            "\n",
            "Inicio de iteracion 80. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = 2\n",
            "\n",
            "Fin de iteracion 80. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = 2 -  error train = 0.6505492096619717 -  error val = 0.4999519283831868\n",
            "\n",
            "Inicio de iteracion 81. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = None\n",
            "\n",
            "Fin de iteracion 81. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = None -  error train = 0.6959001120618292 -  error val = 0.5607328930513437\n",
            "\n",
            "Inicio de iteracion 82. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = 1\n",
            "\n",
            "Fin de iteracion 82. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = 1 -  error train = 0.4912548738098601 -  error val = 0.3619635029134367\n",
            "\n",
            "Inicio de iteracion 83. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = 2\n",
            "\n",
            "Fin de iteracion 83. n_trees = 100, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = 2 -  error train = 0.588977730356179 -  error val = 0.4464640501547922\n",
            "\n",
            "Inicio de iteracion 84. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = None\n",
            "\n",
            "Fin de iteracion 84. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = None -  error train = 0.90259840137739 -  error val = 0.5265775531848327\n",
            "\n",
            "Inicio de iteracion 85. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = 1\n",
            "\n",
            "Fin de iteracion 85. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = 1 -  error train = 0.792383232058818 -  error val = 0.4876102908533352\n",
            "\n",
            "Inicio de iteracion 86. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = 2\n",
            "\n",
            "Fin de iteracion 86. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = 2 -  error train = 0.814605946471926 -  error val = 0.5238231436177048\n",
            "\n",
            "Inicio de iteracion 87. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = None\n",
            "\n",
            "Fin de iteracion 87. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = None -  error train = 0.7718937184871943 -  error val = 0.5530698786499328\n",
            "\n",
            "Inicio de iteracion 88. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = 1\n",
            "\n",
            "Fin de iteracion 88. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = 1 -  error train = 0.5882862266511687 -  error val = 0.43127025585532375\n",
            "\n",
            "Inicio de iteracion 89. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = 2\n",
            "\n",
            "Fin de iteracion 89. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = 2 -  error train = 0.6505492096619717 -  error val = 0.4999519283831868\n",
            "\n",
            "Inicio de iteracion 90. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = None\n",
            "\n",
            "Fin de iteracion 90. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = None -  error train = 0.6959001120618292 -  error val = 0.5607328930513437\n",
            "\n",
            "Inicio de iteracion 91. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = 1\n",
            "\n",
            "Fin de iteracion 91. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = 1 -  error train = 0.4912548738098601 -  error val = 0.3619635029134367\n",
            "\n",
            "Inicio de iteracion 92. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = 2\n",
            "\n",
            "Fin de iteracion 92. n_trees = 100, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = 2 -  error train = 0.588977730356179 -  error val = 0.4464640501547922\n",
            "\n",
            "Inicio de iteracion 93. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = None\n",
            "\n",
            "Fin de iteracion 93. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = None -  error train = 0.7897136489674079 -  error val = 0.5493737289654843\n",
            "\n",
            "Inicio de iteracion 94. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = 1\n",
            "\n",
            "Fin de iteracion 94. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = 1 -  error train = 0.6892400971742241 -  error val = 0.479759139966219\n",
            "\n",
            "Inicio de iteracion 95. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = 2\n",
            "\n",
            "Fin de iteracion 95. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = 2 -  error train = 0.7214200645286994 -  error val = 0.5306680609934089\n",
            "\n",
            "Inicio de iteracion 96. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = None\n",
            "\n",
            "Fin de iteracion 96. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = None -  error train = 0.7478286393621058 -  error val = 0.5567300439376368\n",
            "\n",
            "Inicio de iteracion 97. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = 1\n",
            "\n",
            "Fin de iteracion 97. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = 1 -  error train = 0.5886692104085516 -  error val = 0.43810192459520125\n",
            "\n",
            "Inicio de iteracion 98. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = 2\n",
            "\n",
            "Fin de iteracion 98. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = 2 -  error train = 0.6498720845207107 -  error val = 0.49982829872773005\n",
            "\n",
            "Inicio de iteracion 99. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = None\n",
            "\n",
            "Fin de iteracion 99. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = None -  error train = 0.6959001120618292 -  error val = 0.5607328930513437\n",
            "\n",
            "Inicio de iteracion 100. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = 1\n",
            "\n",
            "Fin de iteracion 100. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = 1 -  error train = 0.4912548738098601 -  error val = 0.3619635029134367\n",
            "\n",
            "Inicio de iteracion 101. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = 2\n",
            "\n",
            "Fin de iteracion 101. n_trees = 100, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = 2 -  error train = 0.588977730356179 -  error val = 0.4464640501547922\n",
            "\n",
            "Inicio de iteracion 102. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = None\n",
            "\n",
            "Fin de iteracion 102. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = None -  error train = 0.9453674839290421 -  error val = 0.523382524989096\n",
            "\n",
            "Inicio de iteracion 103. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = 1\n",
            "\n",
            "Fin de iteracion 103. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = 1 -  error train = 0.8901558722517533 -  error val = 0.4897122909214686\n",
            "\n",
            "Inicio de iteracion 104. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = 2\n",
            "\n",
            "Fin de iteracion 104. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 1, max_features = 2 -  error train = 0.9155733756386015 -  error val = 0.51781054612191\n",
            "\n",
            "Inicio de iteracion 105. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = None\n",
            "\n",
            "Fin de iteracion 105. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = None -  error train = 0.7731911274827126 -  error val = 0.5525886745110492\n",
            "\n",
            "Inicio de iteracion 106. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = 1\n",
            "\n",
            "Fin de iteracion 106. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = 1 -  error train = 0.5888108676881538 -  error val = 0.4242056624727255\n",
            "\n",
            "Inicio de iteracion 107. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = 2\n",
            "\n",
            "Fin de iteracion 107. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 5, max_features = 2 -  error train = 0.6485503519401015 -  error val = 0.4902926402062201\n",
            "\n",
            "Inicio de iteracion 108. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = None\n",
            "\n",
            "Fin de iteracion 108. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = None -  error train = 0.6970760760573003 -  error val = 0.5604647691411826\n",
            "\n",
            "Inicio de iteracion 109. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = 1\n",
            "\n",
            "Fin de iteracion 109. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = 1 -  error train = 0.47834793760132654 -  error val = 0.3397080786318408\n",
            "\n",
            "Inicio de iteracion 110. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = 2\n",
            "\n",
            "Fin de iteracion 110. n_trees = 1000, max_depth = 20, min_samples_split = 2, min_samples_leaf = 20, max_features = 2 -  error train = 0.5821070697542619 -  error val = 0.44207801755620446\n",
            "\n",
            "Inicio de iteracion 111. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = None\n",
            "\n",
            "Fin de iteracion 111. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = None -  error train = 0.9043656239841634 -  error val = 0.5262531117484198\n",
            "\n",
            "Inicio de iteracion 112. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = 1\n",
            "\n",
            "Fin de iteracion 112. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = 1 -  error train = 0.7946411293061661 -  error val = 0.4903441057023664\n",
            "\n",
            "Inicio de iteracion 113. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = 2\n",
            "\n",
            "Fin de iteracion 113. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 1, max_features = 2 -  error train = 0.8193433387072727 -  error val = 0.5201413599824031\n",
            "\n",
            "Inicio de iteracion 114. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = None\n",
            "\n",
            "Fin de iteracion 114. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = None -  error train = 0.7731911274827126 -  error val = 0.5525886745110492\n",
            "\n",
            "Inicio de iteracion 115. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = 1\n",
            "\n",
            "Fin de iteracion 115. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = 1 -  error train = 0.5888108676881538 -  error val = 0.4242056624727255\n",
            "\n",
            "Inicio de iteracion 116. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = 2\n",
            "\n",
            "Fin de iteracion 116. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 5, max_features = 2 -  error train = 0.6485503519401015 -  error val = 0.4902926402062201\n",
            "\n",
            "Inicio de iteracion 117. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = None\n",
            "\n",
            "Fin de iteracion 117. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = None -  error train = 0.6970760760573003 -  error val = 0.5604647691411826\n",
            "\n",
            "Inicio de iteracion 118. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = 1\n",
            "\n",
            "Fin de iteracion 118. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = 1 -  error train = 0.47834793760132654 -  error val = 0.3397080786318408\n",
            "\n",
            "Inicio de iteracion 119. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = 2\n",
            "\n",
            "Fin de iteracion 119. n_trees = 1000, max_depth = 20, min_samples_split = 5, min_samples_leaf = 20, max_features = 2 -  error train = 0.5821070697542619 -  error val = 0.44207801755620446\n",
            "\n",
            "Inicio de iteracion 120. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = None\n",
            "\n",
            "Fin de iteracion 120. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = None -  error train = 0.792123159833201 -  error val = 0.5509308542785484\n",
            "\n",
            "Inicio de iteracion 121. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = 1\n",
            "\n",
            "Fin de iteracion 121. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = 1 -  error train = 0.6936007163317184 -  error val = 0.47916861684434264\n",
            "\n",
            "Inicio de iteracion 122. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = 2\n",
            "\n",
            "Fin de iteracion 122. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 1, max_features = 2 -  error train = 0.7214819140973838 -  error val = 0.5189643922480741\n",
            "\n",
            "Inicio de iteracion 123. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = None\n",
            "\n",
            "Fin de iteracion 123. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = None -  error train = 0.7484338274083989 -  error val = 0.5558447291830958\n",
            "\n",
            "Inicio de iteracion 124. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = 1\n",
            "\n",
            "Fin de iteracion 124. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = 1 -  error train = 0.5873931454251933 -  error val = 0.4245551238704026\n",
            "\n",
            "Inicio de iteracion 125. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = 2\n",
            "\n",
            "Fin de iteracion 125. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 5, max_features = 2 -  error train = 0.646916915477215 -  error val = 0.49140563172874063\n",
            "\n",
            "Inicio de iteracion 126. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = None\n",
            "\n",
            "Fin de iteracion 126. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = None -  error train = 0.6970760760573003 -  error val = 0.5604647691411826\n",
            "\n",
            "Inicio de iteracion 127. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = 1\n",
            "\n",
            "Fin de iteracion 127. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = 1 -  error train = 0.47834793760132654 -  error val = 0.3397080786318408\n",
            "\n",
            "Inicio de iteracion 128. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = 2\n",
            "\n",
            "Fin de iteracion 128. n_trees = 1000, max_depth = 20, min_samples_split = 20, min_samples_leaf = 20, max_features = 2 -  error train = 0.5821070697542619 -  error val = 0.44207801755620446\n",
            "\n",
            "Inicio de iteracion 129. Parametro nrounds = 100, parametro eta = 0.99, parametro gamma = 1, parametro max_depth = 20, parametro min_child_weight = 20, parametro subsample = 0.1, parametro colsample_bytree = 0.1, parametro num_parallel_tree = 20, parametro lambda = 0, parametro alpha = 0\n",
            "\n",
            "[18:29:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Fin de iteracion 129. Parametro nrounds = 100, parametro eta = 0.99, parametro gamma = 1, parametro max_depth = 20, parametro min_child_weight = 20, parametro subsample = 0.1, parametro colsample_bytree = 0.1, parametro num_parallel_tree = 20, parametro lambda = 0, parametro alpha = 0 -  error train = 0.6613992972854712 -  error val = 0.5415215012637046\n",
            "\n",
            "Inicio de iteracion 130. Parametro nrounds = 100, parametro eta = 0.99, parametro gamma = 1, parametro max_depth = 20, parametro min_child_weight = 20, parametro subsample = 0.1, parametro colsample_bytree = 0.1, parametro num_parallel_tree = 20, parametro lambda = 0, parametro alpha = 1\n",
            "\n",
            "[18:29:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Fin de iteracion 130. Parametro nrounds = 100, parametro eta = 0.99, parametro gamma = 1, parametro max_depth = 20, parametro min_child_weight = 20, parametro subsample = 0.1, parametro colsample_bytree = 0.1, parametro num_parallel_tree = 20, parametro lambda = 0, parametro alpha = 1 -  error train = 0.6591363136529618 -  error val = 0.5441694481045649\n",
            "\n",
            "Inicio de iteracion 131. Parametro nrounds = 100, parametro eta = 0.99, parametro gamma = 1, parametro max_depth = 20, parametro min_child_weight = 20, parametro subsample = 0.1, parametro colsample_bytree = 0.1, parametro num_parallel_tree = 20, parametro lambda = 1, parametro alpha = 0\n",
            "\n",
            "[18:30:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Fin de iteracion 131. Parametro nrounds = 100, parametro eta = 0.99, parametro gamma = 1, parametro max_depth = 20, parametro min_child_weight = 20, parametro subsample = 0.1, parametro colsample_bytree = 0.1, parametro num_parallel_tree = 20, parametro lambda = 1, parametro alpha = 0 -  error train = 0.6608870944334022 -  error val = 0.5424376479533819\n",
            "\n",
            "Inicio de iteracion 132. Parametro nrounds = 100, parametro eta = 0.99, parametro gamma = 1, parametro max_depth = 20, parametro min_child_weight = 20, parametro subsample = 0.1, parametro colsample_bytree = 0.1, parametro num_parallel_tree = 20, parametro lambda = 1, parametro alpha = 1\n",
            "\n",
            "[18:30:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "Fin de iteracion 132. Parametro nrounds = 100, parametro eta = 0.99, parametro gamma = 1, parametro max_depth = 20, parametro min_child_weight = 20, parametro subsample = 0.1, parametro colsample_bytree = 0.1, parametro num_parallel_tree = 20, parametro lambda = 1, parametro alpha = 1 -  error train = 0.658500787580356 -  error val = 0.5456656290703406\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "VJ1y0TODmRx3",
        "outputId": "13f73675-08d0-4662-ca4c-f6f96ca5f456"
      },
      "source": [
        "grid_results"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>params</th>\n",
              "      <th>error_train</th>\n",
              "      <th>error_val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>{'regularization': [0]}</td>\n",
              "      <td>0.658786</td>\n",
              "      <td>-2.605362e+25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Linear Regression</td>\n",
              "      <td>{'regularization': [1]}</td>\n",
              "      <td>0.660075</td>\n",
              "      <td>5.533241e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVM</td>\n",
              "      <td>{'C': [0.1], 'gamma': [0.01], 'epsilon': [1]}</td>\n",
              "      <td>-0.869195</td>\n",
              "      <td>2.186688e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SVM</td>\n",
              "      <td>{'C': [0.1], 'gamma': [0.01], 'epsilon': [0.1]}</td>\n",
              "      <td>0.633119</td>\n",
              "      <td>4.762387e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SVM</td>\n",
              "      <td>{'C': [0.1], 'gamma': [0.1], 'epsilon': [1]}</td>\n",
              "      <td>-1.120237</td>\n",
              "      <td>-2.186779e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>random forest</td>\n",
              "      <td>{'n_trees': [1000], 'max_depth': [20], 'min_sa...</td>\n",
              "      <td>0.582107</td>\n",
              "      <td>4.420780e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>xgboost</td>\n",
              "      <td>{'nrounds': [100], 'eta': [0.99], 'gamma': [1]...</td>\n",
              "      <td>0.661399</td>\n",
              "      <td>5.415215e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>xgboost</td>\n",
              "      <td>{'nrounds': [100], 'eta': [0.99], 'gamma': [1]...</td>\n",
              "      <td>0.659136</td>\n",
              "      <td>5.441694e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>xgboost</td>\n",
              "      <td>{'nrounds': [100], 'eta': [0.99], 'gamma': [1]...</td>\n",
              "      <td>0.660887</td>\n",
              "      <td>5.424376e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>xgboost</td>\n",
              "      <td>{'nrounds': [100], 'eta': [0.99], 'gamma': [1]...</td>\n",
              "      <td>0.658501</td>\n",
              "      <td>5.456656e-01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>132 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 model  ...     error_val\n",
              "0    Linear Regression  ... -2.605362e+25\n",
              "1    Linear Regression  ...  5.533241e-01\n",
              "2                  SVM  ...  2.186688e-02\n",
              "3                  SVM  ...  4.762387e-01\n",
              "4                  SVM  ... -2.186779e-01\n",
              "..                 ...  ...           ...\n",
              "127      random forest  ...  4.420780e-01\n",
              "128            xgboost  ...  5.415215e-01\n",
              "129            xgboost  ...  5.441694e-01\n",
              "130            xgboost  ...  5.424376e-01\n",
              "131            xgboost  ...  5.456656e-01\n",
              "\n",
              "[132 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IAx3iDgmShT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "922bb92d-3d50-4d84-fae4-6aa61279dceb"
      },
      "source": [
        "grid_results.groupby(['model'], sort=False)['error_val'].min().sort_values()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model\n",
              "SVM       -0.013814\n",
              "xgboost    0.541522\n",
              "Name: error_val, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P439-P4vmYmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786cb547-f228-45a7-f820-879e411b0498"
      },
      "source": [
        "print(grid_results.iloc[grid_results['error_val'].idxmin()])\n",
        "print('-------------------------------------------')\n",
        "print(grid_results.iloc[grid_results['error_val'].idxmax()])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model                                                     SVM\n",
            "params         {'C': [0.1], 'gamma': [0.1], 'epsilon': [0.1]}\n",
            "error_train                                          0.145268\n",
            "error_val                                          -0.0138139\n",
            "Name: 0, dtype: object\n",
            "-------------------------------------------\n",
            "model                                                    xgboost\n",
            "params         {'nrounds': [100], 'eta': [0.99], 'gamma': [1]...\n",
            "error_train                                             0.658501\n",
            "error_val                                               0.545666\n",
            "Name: 4, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3PDZQepmfFp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1xJtO0h5dDv"
      },
      "source": [
        "Vamos a analizar el mejor resultado para cada familia de modelos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgXyyBZE5U20",
        "outputId": "657970ea-31ef-4e7c-904c-be900f407aba"
      },
      "source": [
        "grid_results.groupby(['model'], sort=False)['error_val'].min().sort_values()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model\n",
              "Linear Regression   -2.605362e+25\n",
              "SVM                 -3.603150e-01\n",
              "decision tree        2.392673e-01\n",
              "random forest        2.917869e-01\n",
              "xgboost              5.415215e-01\n",
              "Name: error_val, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VXSSh7z5lUD"
      },
      "source": [
        "Comparemos el peor y el mejor resultado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuR0EhtO5mpb",
        "outputId": "ae4103b5-6e9c-4b76-b679-a09e89763d40"
      },
      "source": [
        "print(grid_results.iloc[grid_results['error_val'].idxmin()])\n",
        "print('-------------------------------------------')\n",
        "print(grid_results.iloc[grid_results['error_val'].idxmax()])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model                Linear Regression\n",
            "params         {'regularization': [0]}\n",
            "error_train                   0.658786\n",
            "error_val                 -2.60536e+25\n",
            "Name: 0, dtype: object\n",
            "-------------------------------------------\n",
            "model                                              decision tree\n",
            "params         {'max_depth': [20], 'min_samples_split': [2], ...\n",
            "error_train                                             0.702489\n",
            "error_val                                               0.564347\n",
            "Name: 26, dtype: object\n"
          ]
        }
      ]
    }
  ]
}